rm(list= ls())
## Load Packages
library(tidyverse)
library(readxl)
library(janitor)
library(haschaR)
library(sf)
library(stringdist)
library(ggmap)
library(pbapply)
## Declare WDs
wd_t <- 'thomas working directory'
wd_s <- '/Users/saschariaz/Dropbox\ (Harvard\ University)/WW1'
## Set WD
haschaR::detect_wd(wd_h = wd_s,
wd_alt = wd_t,
user_name = 'saschariaz')
## Clean Verlustlisten Data
load('01_Data/Matched\ Entries/Matched_20000_25000.rda')
load('01_Data/Matched\ Entries/Matched_30000_31202.rda')
dat7 <- merged
load('01_Data/Matched\ Entries/Matched_25000_30000.rda')
rm(list= ls())
## Load OCR Data
## Row-bind
load_single('01_Data/Matched\ Entries/Matched_1_5000.RData', 'merged')
dat1 <- merged
load('01_Data/Matched\ Entries/Matched_5000_10000.rda')
dat2 <- matched_5000_10000
load('01_Data/Matched\ Entries/Matched_10000_15000.rda')
dat3 <- merged
load('01_Data/Matched\ Entries/Matched_15000_20000.rda')
dat4 <- merged
load('01_Data/Matched\ Entries/Matched_20000_25000.rda')
dat5 <- merged
load('01_Data/Matched\ Entries/Matched_25000_30000.rda')
dat6 <- merged
load('01_Data/Matched\ Entries/Matched_30000_31202.rda')
dat7 <- merged
dat_all <- mget(ls()[str_detect(ls(), 'dat')])
rawdat <- do.call(rbind, dat_all)
row.names(rawdat) <- NULL
#rawdat <- rawdat[1:1000,]
## Clean Strings
dat <- rawdat %>%
mutate(str = str_replace_all(str, pattern = "ÃŸ", "ss")) %>%
mutate(str = str_replace_all(str, pattern = "[^[:ascii:]]", "")) %>%
mutate(str = str_remove_all(str, pattern = '[.]'))
## Remove strings shorter than length 2
dat <- dat %>%
mutate(str = trimws(gsub('\\b\\w{1,2}\\b','',str))) %>%
filter(nchar(str) > 3)
## Split string elements
dat <- dat %>%
nest(data = c(str)) %>%
mutate(string_elements = pblapply(data, str_split, pattern = ' ')) %>%
unnest()
## Deal with line-breaks
## what we do: we move all string-sequences shorter than length 4 up 1 line
## also insert line break if new line starts in - or previous line ends in -
move_up_ids <- as.character(which(sapply(dat$string_elements, function(x) length(x) <= 3) == 1))
for (i in move_up_ids) {
id <- as.numeric(i)
dat$str[id - 1] <- paste(dat$str[id - 1], dat$str[id], sep = ' ')
dat$str[id] <- NA
}
## Clean Up
dat <- dat %>%
filter(nchar(gsub(" ", "", str)) > 7) %>%
filter(!is.na(str)) %>%
mutate(str = str_remove_all(str, pattern = '-'))
## Split string elements again (now with clean strings)
dat$string_elements <- NULL
dat <- dat %>%
nest(data = c(str)) %>%
mutate(string_elements = pblapply(data, str_split, pattern = ' ')) %>%
unnest()
## Define classes
classes <- c('leicht', 'schwer', 'verwundet', 'tot', 'vermisst', 'gefallen', 'wundt', 'wundet')
## Function assigns most likely class to each row
fun_class <- function(charvec){
input <- unlist(charvec)
classification <- haschaR::fuzzy_string_match(input, classes)
## Choose class with minimal string distance
class_optimal <- classification$match_string[classification$dist_string == min(classification$dist_string)]
dist_optimal  <- classification$dist_string[classification$dist_string == min(classification$dist_string)]
output <- data.frame(class = class_optimal,
string_dist = dist_optimal)
if(length(class_optimal) == 0){
return(c(NA, NA))
}
if(length(class_optimal) == 1){
return(output)
}
if(length(class_optimal) > 1){
return(output[1,])
}
}
## Apply
output <- pblapply(dat$string_elements, fun_class)
## Save This
#saveRDS(output, '01_Data/aa.rds')
output <- do.call(rbind, output)
dat <- cbind(dat, output)
## bad matches = NA
dat$class[dat$string_dist > 1/4] <- NA
# Recode
dat$class_bin = ifelse(dat$class %in% c('tot', 'gefallen', 'vermisst'), 'dead', 'wounded')
dat$class_bin[dat$string_dist > 1/4] <- NA
## Reorder columns
dat <- dat %>%
dplyr::select(-one_of('string_elements', 'string_dist', 'class'))
## Save This
saveRDS(dat, '01_Data/Matched Entries/all_classified.rds')
rm(list= ls())
## Load OCR Data
## Row-bind
haschaR::load_single('01_Data/Matched\ Entries/Matched_1_5000.RData', 'merged')
dat1 <- merged
devtools::install_github('https://github.com/hhilbig/haschaR',
force = T, upgrade = T)
haschaR::nice_load()
library(devtools)
library(roxygen2)
## Declare WDs
wd_h <- '/Users/hanno/Local_Projects/haschaR/'
wd_s <- '/Users/saschariaz/Google\ Drive_Harvard/Git/haschaR'
## Set WD
haschaR::detect_wd(wd_h = wd_h, wd_alt = wd_s, user_name = 'Hanno')
document()
## PUSH BEFORE REINSTALLING
devtools::install_github('https://github.com/hhilbig/haschaR',
force = T, upgrade = T)
devtools::install_github('https://github.com/hhilbig/haschaR',
force = T, upgrade = T)
devtools::install_github('https://github.com/hhilbig/haschaR',
force = T, upgrade = T)
install.packages(c("cli", "clue", "estimatr", "fastDummies", "gh", "globals", "Hmisc", "insight", "isoband", "lme4", "MatchIt", "maxLik", "pillar", "processx", "radiant.data", "rgl", "rlang", "slam"))
install.packages(c("cli", "clue", "estimatr", "fastDummies", "gh", "globals", "Hmisc", "insight", "isoband", "lme4", "MatchIt", "maxLik", "pillar", "processx", "radiant.data", "rgl", "rlang", "slam"))
install.packages(c("cli", "clue", "estimatr", "fastDummies", "gh", "globals", "Hmisc", "insight", "isoband", "lme4", "MatchIt", "maxLik", "pillar", "processx", "radiant.data", "rgl", "rlang", "slam"))
install.packages(c("cli", "clue", "estimatr", "fastDummies", "gh", "globals", "Hmisc", "insight", "isoband", "lme4", "MatchIt", "maxLik", "pillar", "processx", "radiant.data", "rgl", "rlang", "slam"))
devtools::install_github('https://github.com/hhilbig/haschaR',
force = T, upgrade = T)
devtools::install_github('https://github.com/hhilbig/haschaR',
force = T, upgrade = T)
